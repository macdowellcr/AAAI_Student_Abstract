{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa955489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "462feed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (X_train, y_train): (744000, 40) (744000, 1)\n",
      "Testing set shape (X_test, y_test): (186000, 40) (186000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Identify feature and label columns\n",
    "label_columns = [col for col in df.columns if col.startswith('attack_cat')]\n",
    "feature_columns = [col for col in df.columns if not col.startswith('attack_cat')]\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = df[feature_columns]\n",
    "y = df[label_columns]\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape (X_train, y_train):\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape (X_test, y_test):\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d78c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data handling, analysis, and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import scikit-learn modules for preprocessing, model selection, and metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Import the classifier models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7ba1145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\macdo\\anaconda3\\envs\\ml_supervised_20250810\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Performance:\n",
      "Accuracy: 0.8576\n",
      "Weighted F1-Score: 0.8593\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     18457\n",
      "           1       0.67      0.80      0.73     18531\n",
      "           2       0.58      0.68      0.63     18480\n",
      "           3       0.74      0.61      0.67     18468\n",
      "           4       0.83      0.85      0.84     18889\n",
      "           5       1.00      0.98      0.99     18747\n",
      "           6       0.96      0.84      0.90     18578\n",
      "           7       0.93      0.84      0.88     18564\n",
      "           8       0.97      0.99      0.98     18785\n",
      "           9       0.99      0.99      0.99     18501\n",
      "\n",
      "    accuracy                           0.86    186000\n",
      "   macro avg       0.87      0.86      0.86    186000\n",
      "weighted avg       0.87      0.86      0.86    186000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the K-Nearest Neighbors classifier\n",
    "# n_neighbors=5 is a common starting point\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the original, unscaled training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the unscaled test data\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"K-Nearest Neighbors Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}\")\n",
    "print(f\"Weighted F1-Score: {f1_score(y_test, y_pred_knn, average='weighted'):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "# Set zero_division=0 to avoid warnings for labels with no predicted samples\n",
    "print(classification_report(y_test, y_pred_knn, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6331cf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Performance:\n",
      "Accuracy: 0.7540\n",
      "Weighted F1-Score: 0.7546\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18457\n",
      "           1       0.62      0.34      0.44     18531\n",
      "           2       0.38      0.70      0.50     18480\n",
      "           3       0.79      0.44      0.57     18468\n",
      "           4       0.65      0.78      0.71     18889\n",
      "           5       1.00      0.97      0.99     18747\n",
      "           6       0.99      0.74      0.85     18578\n",
      "           7       0.78      0.76      0.77     18564\n",
      "           8       0.77      0.81      0.79     18785\n",
      "           9       0.89      0.98      0.93     18501\n",
      "\n",
      "    accuracy                           0.75    186000\n",
      "   macro avg       0.79      0.75      0.75    186000\n",
      "weighted avg       0.79      0.75      0.75    186000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Decision Tree classifier\n",
    "# Setting a max_depth helps to prevent the tree from overfitting\n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "\n",
    "# Train the model on the original, unscaled training data\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the unscaled test data\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_tree):.4f}\")\n",
    "print(f\"Weighted F1-Score: {f1_score(y_test, y_pred_tree, average='weighted'):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "096e5176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "Accuracy: 0.8756\n",
      "Weighted F1-Score: 0.8777\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18457\n",
      "           1       0.75      0.74      0.74     18531\n",
      "           2       0.57      0.87      0.69     18480\n",
      "           3       0.89      0.59      0.71     18468\n",
      "           4       0.85      0.85      0.85     18889\n",
      "           5       1.00      0.98      0.99     18747\n",
      "           6       0.97      0.88      0.92     18578\n",
      "           7       0.93      0.85      0.89     18564\n",
      "           8       0.97      1.00      0.98     18785\n",
      "           9       1.00      1.00      1.00     18501\n",
      "\n",
      "    accuracy                           0.88    186000\n",
      "   macro avg       0.89      0.88      0.88    186000\n",
      "weighted avg       0.89      0.88      0.88    186000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Random Forest classifier\n",
    "# n_estimators is the number of trees in the forest. n_jobs=-1 uses all available cores.\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model on the training data\n",
    "# .values.ravel() is used to convert the y_train DataFrame to a 1D array, which is expected by the fit method\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Weighted F1-Score: {f1_score(y_test, y_pred_rf, average='weighted'):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_supervised_20250810",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
